# JÃœRÄ° SUNUM AKIÅI - KonuÅŸma Metni

**SÃ¼re:** 7-9 dakika  
**Stil:** DoÄŸal, Ã¶ÄŸrenci dili, kendine gÃ¼venli  
**Format:** Slayt + CanlÄ± Demo

---

## ğŸ¯ SLAYT 1: BAÅLIK (15 saniye)

**Ekran:** BaÅŸlÄ±k slaytÄ±

**KonuÅŸ:**

"Merhaba, ben [Ä°sim]. BugÃ¼n size Profit Tahmini projemi sunacaÄŸÄ±m. SampleSuperstore veri setiyle kÃ¢rlÄ±lÄ±ÄŸÄ± tahmin eden bir regresyon modeli geliÅŸtirdim."

---

## ğŸ“Š SLAYT 2: PROBLEM TANIMI (30 saniye)

**Ekran:** Problem tanÄ±mÄ±

**KonuÅŸ:**

"Problemim ÅŸu: Bir perakende ÅŸirketinin satÄ±ÅŸ verilerini kullanarak kÃ¢rlÄ±lÄ±ÄŸÄ± tahmin etmek istiyorum. Bu bir regresyon problemi Ã§Ã¼nkÃ¼ sÃ¼rekli bir deÄŸer tahmin ediyoruz."

"Neden Ã¶nemli? Ã‡Ã¼nkÃ¼ ÅŸirketler hangi Ã¼rÃ¼nlerin, hangi bÃ¶lgelerin daha karlÄ± olduÄŸunu bilmek istiyor. Bu da stratejik kararlar iÃ§in kritik."

---

## ğŸ’¾ SLAYT 3: VERÄ° SETÄ° (45 saniye)

**Ekran:** Veri seti bilgileri

**KonuÅŸ:**

"Veri setim SampleSuperstore. 9,994 satÄ±r ve 13 kolon var. Sales, Profit, Discount, Quantity gibi sayÄ±sal kolonlar ve Category, Region, Segment gibi kategorik kolonlar mevcut."

"Ä°lk iÅŸim veriyi temizlemek oldu. Eksik deÄŸerleri sayÄ±sal kolonlarda median, kategorik kolonlarda mod ile tamamladÄ±m. Kategorik alanlarda strip yaparak boÅŸluklarÄ± temizledim."

"Outlier'lar iÃ§in IQR yÃ¶ntemi kullandÄ±m ama silmedim - sadece raporladÄ±m. Ã‡Ã¼nkÃ¼ gerÃ§ek dÃ¼nyada aykÄ±rÄ± satÄ±ÅŸlar doÄŸal olabilir."

---

## ğŸ”§ SLAYT 4: FEATURE ENGINEERING (1 dakika)

**Ekran:** Feature engineering aÃ§Ä±klamasÄ±

**KonuÅŸ:**

"Feature engineering kÄ±smÄ±nda veri setinde tarih kolonu olmadÄ±ÄŸÄ± iÃ§in ÅŸu feature'larÄ± tÃ¼rettim:"

"sales_per_item: Her Ã¼rÃ¼nÃ¼n birim fiyatÄ±. Sales'i Quantity'ye bÃ¶ldÃ¼m."

"discounted_sales: Ä°ndirim sonrasÄ± net satÄ±ÅŸ. Sales Ã§arpÄ± 1 eksi Discount."

"profit_margin: Kar marjÄ±. Profit'i Sales'e bÃ¶ldÃ¼m. Ama dikkat - bu feature'Ä± leakage yaratacaÄŸÄ± iÃ§in model eÄŸitiminde drop ettim. Ã‡Ã¼nkÃ¼ doÄŸrudan hedef deÄŸiÅŸkenden tÃ¼retilmiÅŸ."

"is_high_discount: Ä°ndirim yÃ¼zde 30'dan bÃ¼yÃ¼kse 1, deÄŸilse 0. Binary bir flag."

---

## ğŸ¤– SLAYT 5: MODELLEME (1.5 dakika)

**Ekran:** Model mimarisi

**KonuÅŸ:**

"Modelleme kÄ±smÄ±nda sklearn pipeline kullandÄ±m. Kategorik deÄŸiÅŸkenler iÃ§in OneHotEncoder, sayÄ±sal deÄŸiÅŸkenler iÃ§in StandardScaler uyguladÄ±m."

"Ä°ki model denedim: LinearRegression baseline olarak, RandomForestRegressor daha gÃ¼Ã§lÃ¼ bir model olarak."

"Ã–nemli bir nokta: Profit negatif deÄŸerler iÃ§erebildiÄŸi iÃ§in log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ direkt uygulanamÄ±yor. Bu yÃ¼zden shift + log1p kullandÄ±m. Minimum deÄŸer negatifse otomatik shift ekledim."

"Train-test split yÃ¼zde 80-20 yaptÄ±m, random seed 42 ile sabitledi m. Bu sayede sonuÃ§lar tekrar edilebilir."

---

## ğŸ“ˆ SLAYT 6: SONUÃ‡LAR (1.5 dakika)

**Ekran:** Metrik tablosu (Full model)

**KonuÅŸ:**

"SonuÃ§lara bakalÄ±m. LinearRegression baseline olarak Ã§ok zayÄ±f kaldÄ± - RÂ² negatif Ã§Ä±ktÄ±. Bu modelin veri setini aÃ§Ä±klayamadÄ±ÄŸÄ±nÄ± gÃ¶steriyor."

"RandomForest Ã§ok daha iyi performans verdi. RÂ² 0.492, MAE 42.15, RMSE 156.9. Yani modelin yÃ¼zde 49'luk bir aÃ§Ä±klama gÃ¼cÃ¼ var."

"Ama asÄ±l ilginÃ§ kÄ±sÄ±m ablation testinde..."

---

## ğŸ”¬ SLAYT 7: ABLATION TESTÄ° (1.5 dakika)

**Ekran:** Full vs No-Geo karÅŸÄ±laÅŸtÄ±rmasÄ±

**KonuÅŸ:**

"Ablation testi yaptÄ±m. City, State ve Postal Code kolonlarÄ±nÄ± Ã§Ä±karÄ±p modeli tekrar eÄŸittim. Bunlara 'geo kolonlarÄ±' diyorum."

"SonuÃ§ ÅŸaÅŸÄ±rtÄ±cÄ±ydÄ±: Model performansÄ± arttÄ±! RÂ² 0.492'den 0.718'e Ã§Ä±ktÄ±. MAE de 42'den 26'ya dÃ¼ÅŸtÃ¼."

"Neden? Ã‡Ã¼nkÃ¼ geo kolonlarÄ± Ã§ok yÃ¼ksek kardinaliteye sahip - yÃ¼zlerce benzersiz ÅŸehir var. Bu model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± artÄ±rÄ±yor ve overfit'e yol aÃ§Ä±yor."

"Bu sonuÃ§ bana geo bilgisinin bu veri setinde dolaylÄ± etki etse de, Sales, Discount ve tÃ¼rettiÄŸim feature'larÄ±n daha gÃ¼Ã§lÃ¼ olduÄŸunu gÃ¶sterdi."

---

## ğŸ’¡ SLAYT 8: FEATURE IMPORTANCE (1 dakika)

**Ekran:** Top-10 feature importance bar chart

**KonuÅŸ:**

"RandomForest bize hangi feature'larÄ±n Ã¶nemli olduÄŸunu sÃ¶ylÃ¼yor."

"En Ã¶nemli Ã¼Ã§ feature: Sales (0.21), sales_per_item (0.18) ve discounted_sales (0.17). Bunlar benim tÃ¼rettiÄŸim feature'lar ve domain knowledge kullanarak oluÅŸturdum."

"Discount da etkili ama Sales kadar deÄŸil. City_Lancaster gibi bazÄ± ÅŸehirler de Ã¶nemli Ã§Ä±kmÄ±ÅŸ ama bunlar overfit riski taÅŸÄ±yor."

---

## ğŸ¯ SLAYT 9: CANLIDEPO (2 dakika)

**Ekran:** Streamlit uygulamasÄ±

**KonuÅŸ:**

"Åimdi size Ã§alÄ±ÅŸan uygulamayÄ± gÃ¶stereyim."

[DEMO_SCRIPT.md'deki Demo AkÄ±ÅŸÄ±nÄ± Takip Et]

- Veri Ã–zeti sekmesini gÃ¶ster
- EDA grafiklerini gÃ¶ster (Profit daÄŸÄ±lÄ±mÄ±, Sales vs Profit)
- Model SonuÃ§larÄ±nÄ± gÃ¶ster (Full vs No-Geo karÅŸÄ±laÅŸtÄ±rma)
- Feature importance grafiÄŸini gÃ¶ster

**KonuÅŸ:**

"GÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi proje baÅŸtan sona Ã§alÄ±ÅŸÄ±yor. Tek komutla pipeline Ã§alÄ±ÅŸtÄ±rÄ±labilir, sonuÃ§lar tekrar edilebilir."

---

## ğŸ“ SLAYT 10: SONUÃ‡ VE Ã–ZET (45 saniye)

**Ekran:** Ã–zet slaytÄ±

**KonuÅŸ:**

"Ã–zetlersek:"

"9,994 satÄ±rlÄ±k veriyi temizledim, feature engineering yaptÄ±m. LinearRegression ve RandomForest modellerini karÅŸÄ±laÅŸtÄ±rdÄ±m."

"Ablation testi ile geo kolonlarÄ±nÄ± Ã§Ä±karmak modeli iyileÅŸtirdi - RÂ² 0.718'e ulaÅŸtÄ±m."

"Leakage Ã¶nlemi olarak profit_margin'i eÄŸitimden drop ettim. Outlier'larÄ± sildim yerine raporladÄ±m. Log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in shift kullandÄ±m."

"Proje reproducible - tÃ¼m adÄ±mlar random seed ile sabitlendive tek komutla Ã§alÄ±ÅŸtÄ±rÄ±labilir."

"TeÅŸekkÃ¼r ederim. SorularÄ±nÄ±zÄ± alabilirim."

---

## â“ OLASI SORULAR VE CEVAPLAR

### "Overfit riski var mÄ±?"

"RandomForest 200 aÄŸaÃ§ kullanÄ±yor ama min_samples_leaf=2 ve max_features='sqrt' ile sÄ±nÄ±rlandÄ±rdÄ±m. Test/train split yÃ¼zde 80-20 yaptÄ±m. No-Geo senaryoda RÂ² artÄ±ÅŸÄ± overfit azaldÄ±ÄŸÄ±nÄ± gÃ¶steriyor. Ancak cross-validation yapmadÄ±m, bu gelecekte eklenebilir."

### "Neden log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullandÄ±nÄ±z?"

"Profit daÄŸÄ±lÄ±mÄ± saÄŸa Ã§arpÄ±k ve negatif deÄŸerler iÃ§eriyor. log1p direkt uygulanamaz negatif deÄŸerlere. Bu yÃ¼zden minimum deÄŸer negatifse otomatik shift ekliyorum. BÃ¶ylece log dÃ¶nÃ¼ÅŸÃ¼mÃ¼ Ã§alÄ±ÅŸÄ±r ve Ã§arpÄ±k daÄŸÄ±lÄ±mÄ± dÃ¼zeltir."

### "Geo kolonlarÄ±nÄ± neden Ã§Ä±kardÄ±nÄ±z?"

"Ablation testi yaptÄ±m. City/Postal Code gibi alanlar Ã§ok fazla benzersiz deÄŸer iÃ§eriyor - yÃ¼ksek kardinalite. Bu model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± artÄ±rÄ±yor ve genellemeyi zorlaÅŸtÄ±rÄ±yor. No-Geo'da RÂ² 0.718'e Ã§Ä±ktÄ±, yani model daha genellenebilir oldu."

### "Hiperparametre optimizasyonu yaptÄ±nÄ±z mÄ±?"

"Manuel ayar yaptÄ±m ama grid search/random search yapmadÄ±m. RandomForest'te n_estimators=200, min_samples_leaf=2, max_features='sqrt' parametrelerini deneme yanÄ±lmayla belirledim. Grid search yapÄ±labilir ama zaman kÄ±sÄ±tÄ±ndan dolayÄ± manuel yaptÄ±m."

### "Cross-validation neden yok?"

"Zaman kÄ±sÄ±tÄ±. Ama basit train-test split kullandÄ±m ve random seed sabitledim. Cross-validation eklemek sonuÃ§larÄ± daha robust yapardÄ±, bu gelecek iyileÅŸtirme olarak planlanabilir."

---

## ğŸ“Œ SUNUM SIRASINDA DÄ°KKAT!

### Beden Dili
- âœ… JÃ¼riye bak, ekrana deÄŸil
- âœ… Ellerini doÄŸal kullan
- âœ… GÃ¼ven iÃ§inde dik dur
- âœ… GÃ¼lÃ¼mse, rahat ol

### KonuÅŸma Stili
- âœ… Net ve yavaÅŸ konuÅŸ
- âœ… Ã–ÄŸrenci dili kullan (robotik deÄŸil)
- âœ… "Ben yaptÄ±m", "benim yaklaÅŸÄ±mÄ±m" de
- âœ… MeraklÄ± ve hevesli ol

### Teknik Detaylar
- âœ… Metrikleri tam sÃ¶yle (RÂ² 0.718, MAE 42.15)
- âœ… SayÄ±larÄ± vurgula (9,994 satÄ±r, 200 aÄŸaÃ§)
- âœ… Kod gÃ¶sterme (sormadÄ±kÃ§a)
- âœ… Jargon kullan ama aÃ§Ä±kla

---

## â±ï¸ ZAMANLAMA KONTROLÃœ

| Slayt | BÃ¶lÃ¼m | SÃ¼re |
|-------|-------|------|
| 1 | BaÅŸlÄ±k | 15s |
| 2 | Problem | 30s |
| 3 | Veri Seti | 45s |
| 4 | Feature Engineering | 1dk |
| 5 | Modelleme | 1.5dk |
| 6 | SonuÃ§lar | 1.5dk |
| 7 | Ablation | 1.5dk |
| 8 | Feature Importance | 1dk |
| 9 | CanlÄ± Demo | 2dk |
| 10 | SonuÃ§ | 45s |
| **TOPLAM** | | **~9dk** |

---

## ğŸ¬ SON HAZIRLIK

**Sunum Ã¶ncesi 10 dakika:**
1. Derin nefes al, rahat ol
2. Su iÃ§
3. SlaytlarÄ± bir kez gÃ¶zden geÃ§ir
4. Streamlit'i test et
5. GÃ¼ven iÃ§inde sahneye Ã§Ä±k!

**Unutma:** Sen bu projeyi yaptÄ±n, en iyi sen biliyorsun. JÃ¼ri seninle tanÄ±ÅŸmak iÃ§in burada. Rahat ol, kendine gÃ¼ven, baÅŸarÄ±sÄ±n! ğŸ’ªğŸ“
